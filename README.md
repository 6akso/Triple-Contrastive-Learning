##This is the complete code for our paper published in INS, "Triple Contrastive Learning Representation Boosting for Supervised Multiclass Tasks," including experiments in both computer vision (CV) and natural language processing (NLP). You can run the code directly to achieve good results. We have also uploaded models trained with the baseline CE+SCL and our improved method TSI-CL.

##Please note that in our code implementation, to enforce the third-order constraint between negative samples with different labels, we have two forms of the loss function. The second form uses tensors for loss calculation to reduce training time. In this form, the constant term in the denominator of the loss function changes from the number of negative samples for anchor ùë• to the number of pairwise dot product calculations between negative samples with different labels.

##Since all the experiments mentioned in the paper were completed a year ago, and the code was overly complex during the experiments, we have reorganized it. However, this may have introduced some errors.
